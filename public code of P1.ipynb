{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c192068-e88b-4806-8258-e575edf04098",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (37484045.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    ---\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "---\n",
    "\n",
    "## Û². Ù†Ø³Ø®Ù‡ Ù¾Ø§ÛŒØªÙˆÙ† Ø¨Ø§ Ø´Ø±Ø· Ø®Ø·Ø§ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø§Ø¬Ø±Ø§\n",
    "\n",
    "`python\n",
    "raise Exception(\"âš ï¸ Ø§ÛŒÙ† Ú©Ø¯ ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø§Ø³Øª Ùˆ Ø§Ø¬Ø±Ø§ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯!\")\n",
    "\n",
    "import os\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "import spacy\n",
    "\n",
    "print(\"Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ SciSpacy ...\")\n",
    "nlp_spacy = spacy.load(\"en_ner_bionlp13cg_md\")\n",
    "\n",
    "print(\"Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ d4data/biomedical-ner-all ...\")\n",
    "model_id = \"d4data/biomedical-ner-all\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_id)\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "\n",
    "pdf_folder = \"D:/P1\"\n",
    "\n",
    "results = []\n",
    "\n",
    "def split_text(text, max_len=512):\n",
    "    return [text[i:i+max_len] for i in range(0, len(text), max_len)]\n",
    "\n",
    "print(\"Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ PDF ...\")\n",
    "\n",
    "for filename in os.listdir(pdf_folder):\n",
    "    if filename.lower().endswith(\".pdf\"):\n",
    "        print(f\"\\nğŸ“„ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´: {filename}\")\n",
    "        filepath = os.path.join(pdf_folder, filename)\n",
    "        with pdfplumber.open(filepath) as pdf:\n",
    "            full_text = ''\n",
    "            for page in pdf.pages:\n",
    "                text = page.extract_text()\n",
    "                if text:\n",
    "                    full_text += text\n",
    "\n",
    "        keywords = [\"results\", \"funding\", \"findings\", \"interpretation\", \"conclusion\"]\n",
    "        selected_text = ''\n",
    "        for kw in keywords:\n",
    "            idx = full_text.lower().find(kw)\n",
    "            if idx != -1:\n",
    "                selected_text += full_text[idx:idx+2000]\n",
    "        if not selected_text:\n",
    "            selected_text = full_text[:2000]\n",
    "\n",
    "        doc = nlp_spacy(selected_text)\n",
    "        spacy_entities = set([ent.text for ent in doc.ents])\n",
    "        print(f\"ğŸ”¬ SciSpacy: {len(spacy_entities)} Ø¨ÛŒÙˆÙ…Ø§Ø±Ú©Ø± Ù¾ÛŒØ¯Ø§ Ø´Ø¯.\")\n",
    "\n",
    "        ents = []\n",
    "        for chunk in split_text(selected_text):\n",
    "            ents.extend(ner_pipeline(chunk))\n",
    "        d4data_entities = set([ent['word'] for ent in ents])\n",
    "        print(f\"ğŸ¤– d4data NER: {len(d4data_entities)} Ø¨ÛŒÙˆÙ…Ø§Ø±Ú©Ø± Ù¾ÛŒØ¯Ø§ Ø´Ø¯.\")\n",
    "\n",
    "        results.append({\n",
    "            \"Filename\": filename,\n",
    "            \"SciSpacy Biomarkers\": \", \".join(spacy_entities),\n",
    "            \"BiomedNLP Biomarkers\": \", \".join(d4data_entities)\n",
    "        })\n",
    "\n",
    "print(\"\\nğŸ“¦ Ø¯Ø± Ø­Ø§Ù„ Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬ Ø¯Ø± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ ...\")\n",
    "df = pd.DataFrame(results)\n",
    "df.to_excel(\"Extracted_Biomarkers.xlsx\", index=False)\n",
    "df.to_csv(\"Extracted_Biomarkers.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØªÙ…Ø§Ù… Ø´Ø¯.\\nğŸ—‚ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§: Extracted_Biomarkers.xlsx Ùˆ Extracted_Biomarkers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842bf6d4-3a4d-4422-98c5-43b40a5431c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
